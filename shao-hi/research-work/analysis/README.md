Song Title: Reykjavík Sunburn

Artist: marts~ 

Year: 2024

Summary: "Reykjavík Sunburn" is an d&b piece made from a  improv session between the artist and four custom-trained neural audio models. Utilizing a technique the artist calls "Latent Jamming," and AI acts as both a hybrid instrument and an performer.

Technical Analysis
ML Architecture
The RAVE (Realtime Audio Variational autoEncoder) is a deep generative model designed to overcome raw waveform modeling. It utilizes a Variational Autoencoder (VAE) framework consisting of an encoder that transforms audio into a 128-dimensional latent representation and a decoder that reconstructs the signal. To handle high-fidelity 48kHz audio without massive computational overhead, RAVE employs a multi-band decomposition (using 16 bands), which effectively decreases the temporal dimensionality of the data. The decoder is particularly complex, featuring three sub-networks: a waveform conv for the multiband signal, a loudness conv for the amplitude envelope, and a noise synthesizer to improve the naturalness of noisy or "gritty" signals.

Tool Ecosystem
RAVE is specifically engineered to be 20 times faster than real-time on a standard laptop CPU, making it one of the few high-quality models suitable for live "Latent Jamming". The model was trained using the Adam optimizer on a single TITAN V GPU for approximately six days. While the training occurs in a Python environment, the artist utilizes the model within Pure Data (Pd), taking advantage of RAVE's low-latency inference capabilities. This ecosystem allows the artist to bypass the "prohibitively long" sampling procedures of auto-regressive models like WaveNet in favor of immediate, improvisational control.

Data Pipeline
The data pipeline focuses on representation learning from raw waveforms. In marts~’s project, the source data consists of his personal back-catalogue, which is preprocessed through a multiband decomposition to split the signal into decimated sub-signals. A critical feature of the RAVE pipeline is the post-training analysis of the latent space using Singular Value Decomposition (SVD). This allows the artist to identify the most "informative" latent dimensions (often dropping from 128 to as few as 16 or 24 dimensions) to ensure that the parameters he "jams" with have the most significant impact on the sound.

Workflow & Process
Stage 1 : The model is trained as a regular VAE using a multi-scale spectral distance to capture perceptual features like timbre and pitch without being penalized for inaudible phase variations.

Stage 2 : The encoder is frozen, and the decoder is trained against a discriminator (GAN objective) to achieve high-quality, natural sound. This process ensures the latent space is "adequate" before fine-tuning for aesthetics. Human intervention occurs during the performance phase, where the artist navigates the latent(like in the video)  discovered during the SVD analysis to steer the model's output in real-time.

Musical Analysis
Structure
The song is mainly performance-driven, functioning more like a real-time DJ set than a fixed arrangement. Rather than a traditional arrangment, the piece is organized around the layering of some elements including drums, glitch textures, pads, and vocal chops. The "Latent Jamming" practice, where sections evolve based on real-time steering of the models' density and mood. More like an usual drum and bass structure and it's inherently tied to the AI generation method; it is a captured improvisational take where marts~ decides the phrasing and flow by exploring parameter constellations in the latent space.

Musical Elements
While the piece has not much melodic contours and not much of tonal components, it relies on harmonic pads to provide a foundational atmosphere. These pads often based on sawtooth , though they are generated through the "Nobsparse" and "VSC2_Nobsparse" models rather than standard oscillators. The rhythmic patterns are the centerpiece of the composition, generated by the RAVE-based "Black Latents" model which produces intricate, gritty percussive textures characteristic of experimental Drum & Bass. Timbral characteristics are complex and varied, as the RAVE architecture enables high-quality, 48kHz synthesis that captures the specific spectral "DNA" of the artist's own musical back-catalogue.


AI Signatures
The "uncanny valley" effect to me is most audible in the VSC2_Martha2023 model, which reshapes recorded vocal snippets into rhythmic textures; while they sound like a real person's vocal chops, it almost sound like adlib mumbling.This approach performs "Latent Jamming"—morphing between complex timbres and rhythms in ways that would be hard to control by human, in my own experience, it requires alot of routing and placing macros  or usually the loop has already been placed within ableton. However, a significant limitation compared to traditional production is the trade-off between exploration and absolute precision. While the RAVE model is 20 times faster than real-time, it operates as a stochastic "hybrid instrument," meaning the artist must guide and stabilize spontaneous variations rather than having the pixel-perfect control over every drum hit found in standard Drum & Bass production.

Comparative Analysis
"Reykjavík Sunburn" is fundamentally different concept from other AI Song Contest entries that utilize  AI for MIDI or Large Language Models for lyrics. This approach is highly distinctive because it prioritizes the real-time manipulation of raw audio timbres, resulting in an organic sound that avoids sampling familiar. This shifts the focus from writing song with AI to sculpting sound with AI through neural synthesis.Also the artist did not use granular, and traditional Drum & Bass production for improvisational agency. While the RAVE models provide a high degree of automation by spontaneously generating gritty percussion and pads, the human remains essential for steering the "latent trajectories" to control the mood and density. This makes the piece less about rigid scalability or exact reproducibility—since no two sessions in the latent space are identical—and more about a high-fidelity, real-time performance interest.

Ethics and Aesthetics
This project in my opinion requires training the neural networks on his own musical back-catalogue and a private voice dataset, and he ensures that the training data sources are legally and artistically sound. This creates a clear line of creative attribution, as the AI is derived directly from the artist’s own intellectual property. Furthermore, the use of RAVE allows for high-quality synthesis that is 20 times faster than real-time on a standard laptop CPU, significantly reducing the environmental impact of computation compared to energy-intensive, cloud-based generative models.


Innovation Assessment
The primary innovation of "Reykjavík Sunburn" is the application of "Latent Jamming" as a workaround for the static nature of most neural audio generation. By embedding multiple custom RAVE and vschaos2 models within Pure Data , he has developed a novel technique for semi-generative improvisation. This contributes to the field by demonstrating that neural audio models can function as high-fidelity, low-latency instruments rather than just offline tools. The project proves that human/AI agency can be shared in a way that preserves the "uncanny" strengths of machine learning while keeping the human's aesthetic sensibilities at the center of the creative process.