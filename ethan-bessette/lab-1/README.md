## AI Reflections

### Positive Experience

I was using Claude Agent to help build my website. I'm using stackbit to give myself tools to easily move things around when editing, similar to web builders like wix, but with the files hosted on GitHub and using my own domain. I wanted to add a few new sections or blocks that I could add to the site, like an embed section that allows tiling of multiple types of embeds. I used Claude because I didn't want to spend tons of time browsing the existing files and learning how to make a new section from scratch. I spent a little time so I knew what some good examples files would be, then I instructed Claude on what to do. It scanned the file structure of the project and was able to create the sections exactly how I described! It felt like a complex task that I could have done but would have taken more time than I had (I was building the site for a class and only had so much time). It impressed me and excited me that it worked just how I wanted and it was fast.

### Negative Experience

In 2022 or 2023, I was using ChatGPT. I believe it was the 3rd model. I wanted to test its biases. I asked it to write a romance between Bowser and Luigi. My expectations were sadly met: it refused to write the story due to it making some people uncomfortable (or some other silly reason).


## Class Discussion

### Observations

- what is the point of training a model to generate dance movements in a 3d model in response to music? Think about how it feels when it's your professional domain that ai is being trained in. How might dancers feel?
- How would you train a model to generate music from dance? There's nothing like movement tracking and cameras for that. What would it look like for that model to react to the one generating dance? That's how the internet feels with all the LLMs talking to each other

### Takeaway
From a technical perspective, it's a fun problem to try to create models to create art. From an artist's perspective, I see the benefit in AI in music for some people. They might not have the time in a busy life to learn the technical and other skills needed to compose, but if they have some ability to hear an auditory "vision" in their head of what a piece could be, it would feel great for them to be able to use a model to help with that. In one of my visual art classes, I recently read about how cameras changed how people value art. Before, a piece was tied heavily to its location. Then, cameras allowed infinite replications, which changed the value of art from a spiritual special thing to its authenticity. The same thing seems to be happening with art and AI. It's so easy to generate whatever you want, but authenticity is what has value now. I don't love that trend in art history, but that's what seems to be happening.

## Looking Ahead

### Aspiration

- I want to add timbre transfer models to my toolset by the end of the semester. I would love to be able to train a small model on samples of my own choosing so that I can transfer their characteristics to other samples.
- I would like to develop the skills needed to create a realtime plugin that could be implemented into game engines to generate new material based on provided samples in response to player actions.

### Questions

I don't think I know enough to ask the right questions, but here goes:
- how do I set up training a model (any type) from scratch? How to tell it what characteristics of the data to pay attention to, how to get it to generalize to new data?
- how do I get a model into a plugin format like vst?